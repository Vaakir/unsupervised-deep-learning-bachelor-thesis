{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU is activated\n",
      "Number of MRI images:  496\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Duy-Phuong Dao\n",
    "Email: phuongdd.1997@gmail.com (or duyphuongcri@gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "import nibabel as ni\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import torch \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import model\n",
    "#import loss\n",
    "#import dataloader\n",
    "\n",
    "##---------Settings--------------------------\n",
    "batch_size = 8\n",
    "lrate = 0.01\n",
    "epochs = 100\n",
    "weight_decay = 5e-7\n",
    "##############\n",
    "path_data = \"C:/Users/kiran/Documents/_UIS/sem6/BACH/Data/very_spatial_norm/\"\n",
    "path2save = \"C:/Users/kiran/Documents/_UIS/sem6/BACH/Data/_test{}.pt\"\n",
    "dir_info = './infor'\n",
    "os.makedirs(dir_info, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "f = open(os.path.join(dir_info,'model_vae_t1.csv'),'w',newline='')\n",
    "\n",
    "\n",
    "####################\n",
    "verbose = True\n",
    "log = print if verbose else lambda *x, **i: None\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "###################\n",
    "#criterion_rec = loss.L1Loss()\n",
    "#criterion_dis = loss.KLDivergence()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\" GPU is activated\" if device else \" CPU is activated\")\n",
    "no_images = len(glob.glob(path_data + \"/*.nii.gz\"))\n",
    "print(\"Number of MRI images: \", no_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU is activated\n",
      "Number of MRI images:  496\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Duy-Phuong Dao\n",
    "Email: phuongdd.1997@gmail.com (or duyphuongcri@gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "import nibabel as ni\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import torch \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import model\n",
    "import loss\n",
    "import dataloader\n",
    "import visualize\n",
    "##---------Settings--------------------------\n",
    "batch_size = 32\n",
    "##############\n",
    "# path_data = \"/home/ubuntu/Desktop/DuyPhuong/VAE/data/test\"\n",
    "# path_model = \"./checkpoint/vae_t1/model_vae_epoch_43.pt\"\n",
    "path_data = \"C:/Users/kiran/Documents/_UIS/sem6/BACH/Data/very_spatial_norm\"\n",
    "path_model = \"C:/Users/kiran/Documents/_UIS/sem6/BACH/Data/_test/test35.pt\"\n",
    "\n",
    "####################\n",
    "verbose = True\n",
    "log = print if verbose else lambda *x, **i: None\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "###################\n",
    "###################\n",
    "criterion_rec = loss.L1Loss()\n",
    "criterion_dis = loss.KLDivergence()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\" GPU is activated\" if device else \" CPU is activated\")\n",
    "no_images = len(glob.glob(path_data + \"/*.nii.gz\"))\n",
    "print(\"Number of MRI images: \", no_images)\n",
    "if __name__==\"__main__\":\n",
    "    vae_model = torch.load(path_model)\n",
    "    vae_model.to(device)\n",
    "    #log(vae_model)\n",
    "    loss_rec_batch, loss_KL_batch, total_loss_batch = 0, 0, 0\n",
    "    loss_rec, loss_KL, total_loss = 0, 0, 0\n",
    "        \n",
    "    # interfere phrase\n",
    "    vae_model.eval()\n",
    "    z = []\n",
    "    with torch.no_grad():\n",
    "        for batch_images in dataloader.load_mri_images(path_data, batch_size):\n",
    "            print(batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dataloader.load_mri_images(path_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 240, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "file_path = r\"C:\\Users\\kiran\\Documents\\_UIS\\sem6\\BACH\\Data\\_testfew\\35_sub-ADNI003S4872_ses-M120_T1w_brain_brain_restore_norm.nii.gz\"\n",
    "#file_path = r\"C:\\Users\\kiran\\Documents\\_UIS\\sem6\\BACH\\Data\\very_spatial_norm\\3_sub-ADNI002S1261_ses-M132_T1w_brain_brain_restore_norm.nii.gz\"\n",
    "\n",
    "img = nib.load(file_path)\n",
    "img_data = img.get_fdata()\n",
    "img_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
