{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import math\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, k_size, stride=1, p=1, num_groups=1):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(ch_in, ch_out, kernel_size=k_size, stride=stride, padding=p),\n",
    "            nn.BatchNorm3d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "class ResNet_block(nn.Module):\n",
    "    \"A ResNet-like block with the GroupNorm normalization providing optional bottle-neck functionality\"\n",
    "    def __init__(self, ch, k_size, stride=1, p=1, num_groups=1):\n",
    "        super(ResNet_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(ch, ch, kernel_size=k_size, stride=stride, padding=p),\n",
    "            nn.BatchNorm3d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(ch, ch, kernel_size=k_size, stride=stride, padding=p),\n",
    "            nn.BatchNorm3d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x) + x\n",
    "        return out\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"Reduce the number of features by 2 using conv with kernel size 1x1x1 and double the spatial dimension using 3D trilinear upsampling\"\n",
    "    def __init__(self, ch_in, ch_out, k_size=1, scale=2, align_corners=False):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Conv3d(ch_in, ch_out, kernel_size=k_size),\n",
    "            nn.Upsample(scale_factor=scale, mode='trillinear', align_corners=align_corners)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Encoder module\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = conv_block(ch_in=1, ch_out=32, k_size=3, num_groups=1)\n",
    "        self.conv2 = conv_block(ch_in=32, ch_out=64, k_size=3, num_groups=8)\n",
    "        self.conv3 = conv_block(ch_in=64, ch_out=128, k_size=3, num_groups=16)\n",
    "        self.conv4 = conv_block(ch_in=128, ch_out=256, k_size=3, num_groups=16)\n",
    "        \n",
    "        self.res_block1 = ResNet_block(ch=32, k_size=3, num_groups=8)\n",
    "        self.res_block2 = ResNet_block(ch=64, k_size=3, num_groups=16)\n",
    "        self.res_block3 = ResNet_block(ch=128, k_size=3, num_groups=16)\n",
    "        self.res_block4 = ResNet_block(ch=128, k_size=3, num_groups=16)\n",
    "        \n",
    "        self.MaxPool1 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "        self.MaxPool2 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "        self.MaxPool3 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "        self.MaxPool4 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.res_block1(x1)\n",
    "        x1 = self.MaxPool1(x1)\n",
    "        \n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.res_block2(x2)\n",
    "        x2 = self.MaxPool2(x2)\n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.res_block3(x3)\n",
    "        x3 = self.MaxPool3(x3)\n",
    "\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.res_block4(x4)\n",
    "        x4 = self.MaxPool4(x4)\n",
    "        return x4\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"Decoder Module\"\n",
    "    def __init__(self, latent_dim=128, encoder_shape_size = 256 * 13 * 15 * 16):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.linear_up = nn.Linear(latent_dim, encoder_shape_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.upsize4    = up_conv(ch_in=256, ch_out=128, k_size=1, scale=2)\n",
    "        self.upsize3    = up_conv(ch_in=128, ch=64, k_size=1, scale=2)\n",
    "        self.upsize2    = up_conv(ch_in=64, ch=64, k_size=1, scale=2)\n",
    "        self.upsize1    = up_conv(ch_in=32, ch=64, k_size=1, scale=2)\n",
    "\n",
    "        self.res_block4 = ResNet_block(ch_in=128, k_size=3, num_groups=16)\n",
    "        self.res_block3 = ResNet_block(ch=64, k_size=3, num_groups=16)\n",
    "        self.res_block2 = ResNet_block(ch=32, k_size=3, num_groups=16)\n",
    "        self.res_block1 = ResNet_block(ch=1, k_size=3, num_groups=1)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x4_ = self.linear_up(x)\n",
    "        x4_ = self.relu(x4_)\n",
    "\n",
    "        x4_ = x4_.view(-1, 256, 13, 15, 16)\n",
    "        x4_ = self.upsize4(x4_)\n",
    "        x4_ = self.res_block4(x4_)\n",
    "\n",
    "        x3_ = self.upsize3(x4_)\n",
    "        x3_ = self.res_block3(x3_)\n",
    "\n",
    "        x2_ = self.upsize3(x3_)\n",
    "        x2_ = self.res_block3(x2_)\n",
    "\n",
    "        x1_ = self.upsize3(x2_)\n",
    "        x1_ = self.res_block3(x1_)\n",
    "\n",
    "        return x1_\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')        \n",
    "        self.z_mean = nn.Linear( 256 * 13 * 15 * 16, latent_dim)\n",
    "        self.z_log_sigma = nn.Linear( 256 * 13 * 15 * 16, latent_dim)\n",
    "        self.epsilon = torch.normal(size=(1, latent_dim), mean=0, std=1.0, device=self.device)\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        #self.decoder = Decoder(latent_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        # Now, instead of hardcoding, we calculate the output shape of the encoder\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, 1, 208, 240, 256)  # Adjust according to your input shape\n",
    "            output = self.encoder(sample_input)\n",
    "            self.flattened_size = output.numel()  # This calculates the flattened size\n",
    "\n",
    "        # Create linear layers for z_mean and z_log_sigma dynamically\n",
    "        self.z_mean = nn.Linear(self.flattened_size, latent_dim)\n",
    "        self.z_log_sigma = nn.Linear(self.flattened_size, latent_dim)\n",
    "        \"\"\"\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    \n",
    "vae_model = VAE(latent_dim=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (z_mean): Linear(in_features=798720, out_features=128, bias=True)\n",
       "  (z_log_sigma): Linear(in_features=798720, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
