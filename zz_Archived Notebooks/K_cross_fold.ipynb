{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a667bd",
   "metadata": {},
   "source": [
    "### SINCE WE ARE COMPARING MODELS ON MCI, AD, DATA, WE DO NOT NEED TO ADD IN K-FOLD CROSS FOLDING. Since we're not comparing models reconstruction/clustering on CN, but for MCI and AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiran\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORT EVERYTHING\n",
    "from Architectures.AE_ADJ import AE  # for some reason importing this makes it not work? (reconstructs everything around the brain somehow)\n",
    "\n",
    "from Data.load import load, load_middle_slices\n",
    "from Visualizations.latent_space_projections import pPCA, pTSNE, pUMAP, pISOMAP, pENCODED, plot_multiple_datasets\n",
    "from Visualizations.plots import plot_middle_slices_in_range, plot_models_training_time, compare_models_loss_history, plot_images, compare_models_reconstruction\n",
    "from Metrics.metrics_tf import MSE_loss, NMSE_loss, NRMSE_loss, SSIM_loss\n",
    "from Metrics.metrics import NMSE, SSIM, NRMSE, MSE\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras import layers, Model, activations, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import nibabel as nib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3c580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Opening faster: 100%|██████████| 3/3 [00:00<00:00, 32.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "def load_k_fold(\n",
    "        dataset_name:str = \"Pre-processed\",\n",
    "        crop:bool = True,\n",
    "        normalize:bool = True,\n",
    "        #subvoxel_rolling_augmentation:bool = True,\n",
    "        target_size:tuple|None = (80,96,80),\n",
    "        train_test_split:float = 0.9,\n",
    "        take:int=-1,\n",
    "        subdirs=[]\n",
    "        ):\n",
    "    \"\"\"\n",
    "    :params:\n",
    "    - dataset_name: Path relative to this script to the parent folder of the dataset.\n",
    "    - crop: If True: images are cut in all axes s.t. only the non-zero voxels are included.\n",
    "    - normalize: If True: magnitude of voxels are normalized between 0 and 1.\n",
    "    - target_size: Downsampling target size. Set to None to resample to lowest cropped size.\n",
    "    - train_test_split: The ratio of images used in the train set. Set to 1 to include all loaded images in a single dataset.\n",
    "    - take: How many images to load. Set to -1 to load all the images in the dataset.\n",
    "    \"\"\"\n",
    "    #- subvoxel_rolling_augmentation: If True: rolls the images around some times, producing a richer dataset.\n",
    "    if len(subdirs) > 0:\n",
    "        x_train = []\n",
    "        x_test = []\n",
    "        y_train = []\n",
    "        y_test = []\n",
    "        for i, group in enumerate(subdirs):\n",
    "            data = load(\n",
    "                f\"{dataset_name}/{group}\",\n",
    "                crop,\n",
    "                normalize,\n",
    "                target_size,\n",
    "                train_test_split,\n",
    "                take\n",
    "                )\n",
    "            if len(data) == 2:\n",
    "                x_train.extend(data[0])\n",
    "                x_test.extend(data[1])\n",
    "                y_train.extend([i]*len(data[0]))\n",
    "                y_test.extend([i]*len(data[1]))\n",
    "            else:\n",
    "                x_train.extend(data)\n",
    "                y_train.extend([i]*len(data))\n",
    "\n",
    "        y_train = utils.to_categorical(y_train)\n",
    "        y_test = utils.to_categorical(y_test)\n",
    "        x_train = np.stack(x_train)\n",
    "        x_test = np.stack(x_test)\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))  # Get the directory of this script\n",
    "    dataset_path = os.path.join(script_dir, dataset_name)  # Create the absolute path\n",
    "    files = glob(os.path.join(dataset_path, \"*.nii.gz\"))  # Use absolute path for glob\n",
    "    if take >= 0:\n",
    "        files = files[:take]\n",
    "\n",
    "    images = []\n",
    "\n",
    "    def handle_image(img):\n",
    "        if crop:\n",
    "            brain_mask = img > 0.01\n",
    "            bounds = np.where(brain_mask)\n",
    "            x_min, x_max, y_min, y_max, z_min, z_max = np.min(bounds[0]), np.max(bounds[0]), np.min(bounds[1]), np.max(bounds[1]), np.min(bounds[2]), np.max(bounds[2])\n",
    "            img = img[x_min-2:x_max+3, y_min-2:y_max+3, z_min-2:z_max+3]\n",
    "\n",
    "        '''\n",
    "        if subvoxel_rolling_augmentation:\n",
    "            # Since we zoom the image, we can nudge the picture in various directions to\n",
    "            # achieve new sub-pixel level information in the output :)\n",
    "            for roll in range(2):\n",
    "                for axis in range(3):\n",
    "                    loaded_images.append(np.roll(img, roll*2, axis))\n",
    "        '''\n",
    "                    \n",
    "        if normalize:\n",
    "            q2m = .785700/.475665\n",
    "            fac = np.min([q2m / np.quantile(img,0.98), 1. / np.max(img)])\n",
    "            img *= fac\n",
    "            \n",
    "        if target_size != None:\n",
    "            zoom_factors = [t / b for t, b in zip(target_size, img.shape)]\n",
    "            img = zoom(img, zoom_factors, order=1)  # Linear interpolation\n",
    "\n",
    "\n",
    "        return [img]\n",
    "    \n",
    "    desc = f\"Loading {dataset_name.split('/')[-1]}\"\n",
    "    for file in tqdm(files, desc):\n",
    "        img = nib.load(file).get_fdata()\n",
    "        images.extend(handle_image(img))\n",
    "\n",
    "    images = np.stack(images)\n",
    "    if train_test_split>=1 or train_test_split<=0: return images\n",
    "\n",
    "    idx_split = int(len(images) * train_test_split)\n",
    "    train, test = images[:idx_split], images[idx_split:]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "groups = {}\n",
    "for group in tqdm([\"CN\",\"MCI\",\"AD\"],\"Opening faster\"):\n",
    "    groups[group]=np.load(open(f\"Data/D2-{group}-A.npy\",\"br\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aae3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Pre-processed: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "\n",
    "take = 100\n",
    "normalize = True\n",
    "dataset_name = \"Pre-processed\"\n",
    "crop = True\n",
    "normalize=  True\n",
    "#subvoxel_rolling_augmentation:bool = True,\n",
    "target_size= (80,96,80)\n",
    "train_test_split= 0.9\n",
    "take: -1\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))  # Get the directory of this script\n",
    "#dataset_path = os.path.join(script_dir, dataset_name)  # Create the absolute path\n",
    "\n",
    "dataset_path = r\"C:\\Users\\kiran\\Documents\\_UIS\\sem6\\BACH\\DementiaMRI\\Data\\Pre-processed-CN\"\n",
    "files = glob(os.path.join(dataset_path, \"*.nii.gz\"))\n",
    "if take >= 0:\n",
    "    files = files[:take]\n",
    "\n",
    "image_ids = []\n",
    "for file in files:\n",
    "    #C:\\\\blabla\\106_ADNI_116_S_0487_blabla.nii.gz -> 116_S_0487_MR_blabla.nii.gz -> 116_S_0487 (pID)\n",
    "    #C:\\1_sub-ADNI002S0413_ses-M132_T1w2_norm.nii.gz -> C:\\1_sub_ADNI002S0413_ses-M132_T1w2_norm.nii.gz -> 002S0413_ses-M132_T1w2_norm.nii.gz -> 002S0413\n",
    "    if \"_sub-ADNI\" in file:\n",
    "        file = file.split(\"_sub-ADNI\")[-1]\n",
    "        file = file.split(\"_ses\")[0] # 002S0413\n",
    "        file_id = \"_S_\".join(file.split(\"S\"))\n",
    "    elif \"_ADNI_\" in file:\n",
    "        file = file.split(\"_ADNI\")[-1]\n",
    "        file_id = file.split(\"_MR\")[0]\n",
    "    else:\n",
    "        print(f\"Problems extracting id from {file}\")\n",
    "        file_id = 0\n",
    "    image_ids.append(file_id)\n",
    "\n",
    "images = []\n",
    "\n",
    "def handle_image(img):\n",
    "    if crop:\n",
    "        brain_mask = img > 0.01\n",
    "        bounds = np.where(brain_mask)\n",
    "        x_min, x_max, y_min, y_max, z_min, z_max = np.min(bounds[0]), np.max(bounds[0]), np.min(bounds[1]), np.max(bounds[1]), np.min(bounds[2]), np.max(bounds[2])\n",
    "        img = img[x_min-2:x_max+3, y_min-2:y_max+3, z_min-2:z_max+3]\n",
    "\n",
    "    '''\n",
    "    if subvoxel_rolling_augmentation:\n",
    "        # Since we zoom the image, we can nudge the picture in various directions to\n",
    "        # achieve new sub-pixel level information in the output :)\n",
    "        for roll in range(2):\n",
    "            for axis in range(3):\n",
    "                loaded_images.append(np.roll(img, roll*2, axis))\n",
    "    '''\n",
    "                \n",
    "    if normalize:\n",
    "        q2m = .785700/.475665\n",
    "        fac = np.min([q2m / np.quantile(img,0.98), 1. / np.max(img)])\n",
    "        img *= fac\n",
    "        \n",
    "    if target_size != None:\n",
    "        zoom_factors = [t / b for t, b in zip(target_size, img.shape)]\n",
    "        img = zoom(img, zoom_factors, order=1)  # Linear interpolation\n",
    "\n",
    "\n",
    "    return [img]\n",
    "\n",
    "desc = f\"Loading {dataset_name.split('/')[-1]}\"\n",
    "for file in tqdm(files, desc):\n",
    "    img = nib.load(file).get_fdata()\n",
    "    images.extend(handle_image(img))\n",
    "\n",
    "images = np.stack(images)\n",
    "if train_test_split>=1 or train_test_split<=0: \n",
    "    pass\n",
    "    #return images\n",
    "\n",
    "#return train, test\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "train_test_folds = []\n",
    "for train_idx, test_idx in gkf.split(images, y=np.zeros(len(images)), groups=image_ids):\n",
    "    X_train, X_test = images[train_idx], images[test_idx]\n",
    "    train_test_folds.append((X_train, X_test))\n",
    "    #print(len(X_train), len(X_test),\"\\n\", train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "take = 10\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))  # Get the directory of this script\n",
    "#dataset_path = os.path.join(script_dir, dataset_name)  # Create the absolute path\n",
    "dataset_path = r\"C:\\Users\\kiran\\Documents\\_UIS\\sem6\\BACH\\DementiaMRI\\Data\\Pre-processed-AD\"\n",
    "files = glob(os.path.join(dataset_path, \"*.nii.gz\"))  # Use absolute path for glob\n",
    "if take >= 0:\n",
    "    files = files[:take]\n",
    "\n",
    "images = []\n",
    "\n",
    "def handle_image(img):\n",
    "    if crop:\n",
    "        brain_mask = img > 0.01\n",
    "        bounds = np.where(brain_mask)\n",
    "        x_min, x_max, y_min, y_max, z_min, z_max = np.min(bounds[0]), np.max(bounds[0]), np.min(bounds[1]), np.max(bounds[1]), np.min(bounds[2]), np.max(bounds[2])\n",
    "        img = img[x_min-2:x_max+3, y_min-2:y_max+3, z_min-2:z_max+3]\n",
    "\n",
    "    '''\n",
    "    if subvoxel_rolling_augmentation:\n",
    "        # Since we zoom the image, we can nudge the picture in various directions to\n",
    "        # achieve new sub-pixel level information in the output :)\n",
    "        for roll in range(2):\n",
    "            for axis in range(3):\n",
    "                loaded_images.append(np.roll(img, roll*2, axis))\n",
    "    '''\n",
    "                \n",
    "    if normalize:\n",
    "        q2m = .785700/.475665\n",
    "        fac = np.min([q2m / np.quantile(img,0.98), 1. / np.max(img)])\n",
    "        img *= fac\n",
    "        \n",
    "    if target_size != None:\n",
    "        zoom_factors = [t / b for t, b in zip(target_size, img.shape)]\n",
    "        img = zoom(img, zoom_factors, order=1)  # Linear interpolation\n",
    "\n",
    "\n",
    "    return [img]\n",
    "\n",
    "desc = f\"Loading {dataset_name.split('/')[-1]}\"\n",
    "for file in tqdm(files, desc):\n",
    "    img = nib.load(file).get_fdata()\n",
    "    images.extend(handle_image(img))\n",
    "\n",
    "images = np.stack(images)\n",
    "if train_test_split>=1 or train_test_split<=0: return images\n",
    "\n",
    "idx_split = int(len(images) * train_test_split)\n",
    "train, test = images[:idx_split], images[idx_split:]\n",
    "\n",
    "return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504158b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train3D, H_test3D = load(dataset_name=\"Pre-processed\", train_test_split=0.8, take=take)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load all images in a list, also have another list for the patient ids, then \n",
    "# 1_ADNI_002_S_1018_MR_MPR____N3__Scaled_Br_20070217032215330_S24312_I408282_norm.nii.gz\n",
    "# 002_S_1018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = array of images\n",
    "# y = optional labels #(you might not have these if it's unsupervised)\n",
    "# groups = patient IDs corresponding to each image\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for train_idx, test_idx in gkf.split(X, y, groups=patient_ids):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "# for train_idx, test_idx in gkf.split(X, y=np.zeros(len(X)), groups=patient_ids):\n",
    "#     X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "import re\n",
    "def extract_patient_id(filename):\n",
    "    match = re.search(r'\\d{3}_S_\\d{4}', filename)\n",
    "    return match.group(0) if match else None\n",
    "filename = \"1_ADNI_002_S_1018_MR_MPR____N3__Scaled_Br_20070217032215330_S24312_I408282_norm.nii.gz\"\n",
    "patient_id = extract_patient_id(filename)\n",
    "print(patient_id)  # ➜ 002_S_1018\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
